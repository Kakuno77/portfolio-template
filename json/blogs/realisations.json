{
  "slug": "realisations",
  "title": "Mes réalisations",
  "content": {
      "articles": [
          {
              "banner": {
                  "headline": "lorem ipsum dolor amet",
                  "image": {
                      "src": "",
                      "alt": ""
                  }
              },
              "title": "Migration de broker NGSI-LD",
              "customCss": {},
              "direction": "row",
              "elements": [
                  {
                      "type": "text",
                      "sort": 2,
                      "content": "<p>La migration de Stellio vers Orion, deux brokers NGSI-LD, représente une étape importante pour notre infrastructure de gestion de données.</br>Cette migration, réalisée sur un cluster Kubernetes, a permis de renforcer notre capacité à traiter et à gérer de grandes quantités de données contextuelles.</br>Cet article explique pourquoi et comment cette migration a été réalisée, les défis rencontrés et les bénéfices obtenus.<h2>Qu'est-ce qu'un Broker NGSI-LD ?</h2>Avant de plonger dans les détails techniques, il est essentiel de comprendre ce qu'est un broker NGSI-LD.</br>Les brokers NGSI-LD, comme Stellio et Orion, sont des composants logiciels essentiels pour la gestion des données contextuelles dans les applications de l'Internet des Objets (IoT).</br>Ils permettent de collecter, stocker, gérer et interroger des données contextuelles en utilisant le standard NGSI-LD.<h2>Pourquoi Migrer de Stellio à Orion ?</h2>Stellio et Orion sont deux implémentations de brokers NGSI-LD, chacune avec ses propres avantages et inconvénients.</br>La décision de migrer de Stellio à Orion a été motivée par plusieurs facteurs :<li><b>Performance</b> : Orion offre des performances supérieures en termes de traitement et de gestion des données contextuelles.</li><li><b>Compatibilité</b> : Orion est largement adopté et offre une meilleure compatibilité avec d'autres composants de notre écosystème technologique.</li><li><b>Support et Communauté</b> : Orion bénéficie d'un support actif et d'une communauté dynamique, facilitant la résolution des problèmes et l'accès aux nouvelles fonctionnalités.</li><h2>Le Processus de Migration</h2>La migration de Stellio à Orion sur Kubernetes a été réalisée en plusieurs étapes :<li><b>Planification et Préparation</b> : Une analyse approfondie a été effectuée pour comprendre les dépendances et les configurations requises. Un plan de migration détaillé a été élaboré.</li><li><b>Installation d'Orion</b> : Orion a été déployé sur Kubernetes en utilisant des fichiers de configuration YAML pour définir les déploiements, les services et les configurations nécessaires.</li><li><b>Migration des Données</b> : Les données existantes dans Stellio ont été exportées et importées dans Orion. Des scripts ont été utilisés pour automatiser ce processus et garantir l'intégrité des données.</li><li><b>Tests et Validation</b> : Des tests rigoureux ont été effectués pour s'assurer que toutes les données ont été migrées correctement et que Orion fonctionnait comme prévu.</li><li><b>Mise en Production</b> : Une fois les tests réussis, Orion a été mis en production et Stellio désinstallé. Une surveillance continue a été mise en place pour détecter et résoudre rapidement tout problème.</li><h2>Ce qu'on en a tiré</h2>Comme toute migration, celle-ci n'était pas sans défis, certaines structures de données dans Stellio n'étaient pas directement compatibles avec Orion, nécessitant des transformations spécifiques.</br>Assurer que toutes les dépendances externes fonctionnaient correctement avec Orion a demandé des ajustements et des tests supplémentaires.</br>Enfin nous avons travaillé pour minimiser les interruptions de service, en planifiant les migrations pendant les périodes de faible activité.</br>Cependant la migration vers Orion a apporté plusieurs bénéfices significatifs comme</br>Les temps de réponse pour les requêtes de données contextuelles ont été réduits, améliorant l'expérience utilisateur.</br>Meilleure Gestion des Données : Orion offre des fonctionnalités avancées pour la gestion et l'interrogation des données, facilitant les analyses et les décisions basées sur les données.</p>",
                      "customCss": {}
                  }
              ]
          },
          {
              "banner": {
                  "headline": "lorem ipsum dolor amet",
                  "image": {
                      "src": "/img/K8S-logo.png",
                      "alt": ""
                  }
              },
              "title": "Migration d'un cluster kubernetes",
              "customCss": {},
              "direction": "row",
              "elements": [
                  {
                      "type": "text",
                      "sort": 2,
                      "content": "<p>Dans le cadre de l'évolution de nos besoins en termes de performances et de scalabilité, nous avons récemment entrepris la migration d'un de nos clusters Kubernetes vers une infrastructure plus puissante.</br>Ce projet a été motivé par l'augmentation continue de la consommation de processeur et de RAM requis pour satisfaire les besoins de nos différents clients.<h2>Planification et Préparation</h2>La migration a été minutieusement planifiée par la direction des systèmes informatiques ainsi que l'équipe technique pour répondre à leurs exigences.</br>Les principaux objectifs identifiés étaient de garantir une transition fluide, de valider la pertinence des outils existants, et de mettre à jour les composants obsolètes.</br>Un aspect crucial de la préparation a été la sauvegarde des données. Les données des différents déploiements de notre ancien cluster étaient sauvegardées quotidiennement sur un bucket, un conteneur de stockage d'objets. Nous avons vérifié que ces sauvegardes pouvaient être restaurées sans problème, garantissant ainsi l'intégrité des données durant la migration.<h2>Mise en Place du Nouveau Cluster</h2>La première étape technique a consisté à installer Kubernetes sur notre nouvelle machine.</br>Cette installation a été réalisée via un <b>pipeline CI/CD (Intégration Continue/Livraison Continue)</b> spécialement conçu pour automatiser les processus nécessaires.</br>Ce pipeline exécutait des jobs pour réinstaller les différentes applications conteneurisées qui composent la plateforme.</br>L'automatisation a joué un rôle clé dans la réinstallation des composants.</br>Dès le lancement des jobs, les applications conteneurisées ont été automatiquement déployées sur le nouveau cluster.</br> Une fois l'installation terminée, nous avons procédé à des vérifications pour nous assurer que toutes les applications fonctionnaient correctement.<h2>Migration des Données et Vérifications</h2>Après la réinstallation des composants, l'étape suivante a été de restaurer les backups sur le nouveau cluster.</br>Ce processus a été réalisé en tirant les sauvegardes précédemment stockées sur le bucket vers la nouvelle infrastructure.</br>Cette étape cruciale a permis de transférer en toute sécurité les données de l'ancien cluster vers le nouveau.</br>Une fois les données restaurées, nous avons effectué des tests approfondis pour vérifier le bon fonctionnement des applications et la conformité des données.</br>Ces tests ont confirmé que la migration s'était déroulée sans accrocs.<h2>Conclusion et Expertise</h2>En résumé, cette migration de cluster Kubernetes a été un succès grâce à une planification rigoureuse et à l'automatisation des processus.</br>Mon expertise couvre l'ensemble des opérations de déploiement, de backup et de monitoring, où je me considère à un niveau intermédiaire.</br>Cependant, en ce qui concerne les opérations de routage telles que l'utilisation de reverse proxies ou de load balancers, je me situe encore à un niveau débutant.</br>Cette expérience enrichissante a renforcé nos compétences et notre capacité à répondre aux besoins croissants de nos clients, tout en garantissant la performance et la fiabilité de leurs applications.</p>",
                      "customCss": {}
                  }
              ]
          },
          {
              "banner": {
                  "headline": "lorem ipsum dolor amet",
                  "image": {
                      "src": "/img/compiler.png",
                      "alt": ""
                  }
              },
              "title": "Développement d'un compilateur source à source",
              "customCss": {},
              "direction": "row",
              "elements": [
                  {
                      "type": "text",
                      "sort": 3,
                      "content": "Durant mon cursus de développeur à L’ESIEA, j’ai eu l’occasion de développer un compilateur “Code maison” vers le langage Javascript. Pour ma part, je suis un grand passionné par l'étude des algorithmes ainsi que l’utilisation de diverses structures de données. Ainsi, ce projet m’a permis de comprendre et utiliser les arbres syntaxiques, qu’on verra plus en détail ci-dessous.\t<h1>Qu’est-ce qu’un compilateur  source à source</h1><p>Un compilateur source à source est un programme qui va convertir un programme écrit dans un langage A, vers un langage B. L’exemple le plus connu aujourd’hui étant Babel JS, un compilateur qui sait convertir du code Javascript d’une certaine version vers un code Javascript d’une version antérieure, permettant d’assurer la rétrocompatibilité sur des moteurs javascript plus anciens. Un compilateur suit des étapes précises.</p>\t<h2>L’analyse lexicale</h2><p>Pour chaque instruction, le compilateur identifie chaque <b>lexème</b> (mot) de l’instruction. Exemple : <div class='blog-img-wrapper'><img class='blog-img' src='/img/ex_langage_naturel.jpg'></div> Ci-dessus, on identifie chaque <b>lexème</b> (mot) de la phrase “Pierre aime-t-il ( un peu ) les pommes ?” en leur attribuant une nature (une classification, ex : adverbe).</p>\t<h2>L’analyse syntaxique</h2>\t<p>L’analyse syntaxique se base sur la forme des instructions. Autrement dit, il faut que chaque <b>lexème</b> présent dans chaque instruction soit placé dans un ordre qui lui donne du sens. En reprenant l’exemple de la phrase “Pierre aime-t-il ( un peu ) les pommes ?”,  ça ne ferait pas sens si on plaçait un autre <b>lexème</b> que “Pierre” en début de phrase (sans rajouter de majuscule pour compenser l’incohérence, on inverse seulement l’ordre de deux mots), comme “aime” par exemple, car toute phrase commence par une majuscule et se termine par un point, ce qui donnerait “aime Pierre -t-il (un peu) les pommes ?”...</p>\t<h2>L’analyse sémantique</h2><p>L’analyse sémantique est complémentaire à l’analyse syntaxique, et se base elle sur le fond des instructions. Dans cette étape, on vérifie si les <b>lexèmes</b> ont un sens dans leur contexte. Pour prendre un exemple réel, dans notre code maison, on aura affaire à des déclarations de variables. Les variables peuvent avoir plusieurs types (entier, chaîne de caractères, booléens etc.). <p>L’expression <b>“entier A = 5”</b> fait sens, car on déclare une variable “A” de type entier, et on lui stock la valeur 5, qui est bien un entier.</p><p>L’expression <b>“entier A = 5+9-2”</b> est également bonne, car on fait une opération d’addition ainsi qu’une opération de soustractions sur des entiers, et seulement des entiers.</p>Cependant, l’instruction <b>“entier A = bonjour’”</b> est sémantiquement incorrecte, bien qu’elle soit syntaxiquement correcte. En effet, on déclare une variable de type entier, mais on lui affecte une chaîne de caractère. Il y a ici incohérence des types et donc erreur ! <p>Autre exemple, l’instruction <b>“entier A = 5 + ‘bonjour’”</b> est sémantiquement incorrecte car on additionne un entier à une chaîne de caractère, qu’on stocke ensuite dans une variable de type entier.</p><p>Pour prendre un exemple un peu plus compliqué, l’instruction: <b>“chaine A = 5 + ‘bonjour’”</b> pourrait être jugé comme fausse par notre compilateur, bien que ce genre d’instruction est toléré dans beaucoup de langage de programmation aujourd’hui, car ici, on additionne un entier à une chaine de caractere et on l’assigne à une variable de type “chaine”. Dans la majorité des langages de programmation existants, on appelle celà de la concaténation de chaînes de caracteres, c’est-à-dire qu’on vient ajouter au début de  la chaine de caractère “bonjour”, l’entier 5, qui se retrouve automatiquement “converti” en caractère par le compilateur. Notre variable “A” contiendra donc la chaine de caractère “5bonjour”, ce qui est valide sémantiquement parlant.</p><p>Pour finir, on va revenir sur l’exemple de la phrase concernant Pierre. En plein milieu de la phrase “Pierre aime t-il (un peu) les pommes”, nous pouvons constater un groupe de mots “(un peu)” très suspicieux. En effet, syntaxiquement il n y a pas de problème à insérer une parenthèse ouvrante et fermante ainsi que plusieurs mots entre ces parenthèses. Néanmoins, on comprend rapidement que sémantiquement parlant il y a un problème, car cela ne fait pas sens de dire “(un peu)” en plein milieu de cette phrase particulièrement. Il faut bien distinguer syntaxe et sémantique. Dans la sémantique, on s'intéresse vraiment au sens profond de chaque <b>lexème</b> par rapport aux autres <b>lexèmes</b> tandis que dans la syntaxe, on observe simplement l'ordre des <b>lexèmes</b> et la grammaire.</p>\t<h1>Quelques fonctionnalités développées</h1><p>Un programme est un ensemble d’instructions destinées à être exécutées une par une par le processeur. Dans les langages de programmation, chaque instruction a une syntaxe spécifique. Voilà quelques exemples dans le langage Javascript: <li>pour déclarer une variable “A” contenant la valeur 45: <b>let A = 45</b></li><li>Pour effectuer une addition et stocker son résultat dans une variable “B”: <b>let B = 5 + 9</b></li><li>ecrire une condition si, sinonsi, sinon: <b>if (a == b){ … } else if {} else {}</b></li><li>Ecrire une boucle itérative: <b>for (let i = 0; i &#60; 10; i++) {...}</b></li> <br>Bien évidemment, pour développer un compilateur il faut bien fixer des règles syntaxiques précises, chose que j’ai faite avant de commencer le travail. On verra rapidement les règles que j’ai fixées pour mon “code maison”. Sans trop tarder, voici quelques fonctionnalités prises en compte pour ce compilateur : <h3>Analyse lexicale/syntaxique :</h3><li>opérateurs binaire</li> <li>appel de fonction</li><li>opérateur binaire (+, -, &#62;=, &#62;, &#60;, &#60;=, ==, *, \/, ET, OU)</li><li>définition de fonction (fonction mafonction (entier a) : entier { } )</li><li>déclaration de variable / initialisation (entier a; entier b = 1;)</li><li>affectation (b = 2)</li><li>branchement (si / sinon si / sinon)</li><li>boucle (tantque () { })</li><li>retourner</li><li>variable de type entier SEULEMENT</li> <h3>Analyse sémantique :</h3><li>Vérification des variables (declaration/redeclaration) dans les boucles, conditions, fonctions et appels de fonctions.</li><li>Vérification des fonctions (declaration/appel)</li></p><h1>Technologies utilisées</h1></h2><p>J’ai développé ce compilateur en langage C, langage bas niveau privilégié pour ses  bonnes performances, notamment dans les projets d'électronique embarqué. Pour compiler le code écrit en C, j’ai utilisé le compilateur bien connu “GCC”. De plus, j'ai utilisé l’outil populaire “Make” qui permet de produire des exécutables à partir de fichiers source. Cet outil est très pratique lorsque notre programme comporte de nombreux fichiers source. Dans ce cas, sans Make, on devrait écrire en entier une longue ligne de commande pour compiler chaque fichier. C’est là que Make intervient, car on a juste à lui fournir des règles, chaque règle étant associée à une ligne de commande. De ce fait, en moins de 10 secondes, on peut compiler un logiciel et le rendre exécutable.</p>\t<h1>Les arbres syntaxiques</h1><p>On en vient au fameux sujet qui m’a motivé à mener à terme ce projet jusqu’au bout : les arbres syntaxiques. Comment notre compilateur va-t-il procéder pour convertir du code maison en javascript ? L’idée globale est que le compilateur parcourt de haut en bas chaque ligne de code. On appelle ce procédé le “Parsing”. Durant tout le processus de parsing, il va alors construire une liste chainée, et pour chaque ligne de code, il va créer un “noeud”. Un nœud comporte une racine, et des feuilles. La racine représente la nature de notre expression (ligne de code pour faire plus simple) tandis que les feuilles vont décrire en détail l’expression. <div class='blog-img-wrapper'><img class='blog-img' src='/img/noeud_ast.jpg'><i>un noeud de notre arbre</i></div></br>Par exemple, ci-dessus, un nœud décrivant une opération, plus précisément une addition. En partant de la gauche vers la droite, on lit “5+4”. Au fur et à mesure qu’on va parser le code maison, on construit un nœud pour chaque instruction. À la fin, on se retrouve avec un arbre complet. Une fois cet arbre complet, on a juste à le parser (parcourir) de haut en bas pour ainsi générer le code Javascript. Il faut noter que durant cette étape, on est à l'étape de l’analyse lexicale + syntaxique. En effet, on effectue l’analyse lexicale et syntaxique en simultané pour chaque instruction. Une fois toute cette étape terminée et notre arbre syntaxique entièrement généré, on peut passer à l’analyse sémantique. Dans l’analyse sémantique d’un langage de programmation, et dans le cadre de mon projet, on va seulement vérifier la cohérence des types (comme évoqué plus haut).</p> <h1>Génération du code Javascript</h1><p>Félicitations, nous avons notre arbre syntaxique qui a été analysé syntaxiquement et sémantiquement. À présent, on peut générer le code javascript. Cette étape est la plus simple et la plus rapide. On parcourt notre arbre et pour chaque nœud dans l’arbre, on génère le code javascript suivant. <div class='blog-img-wrapper'><img class='blog-img' src='/img/ex_ast.jpg'><i>Exemple d’un arbre syntaxique généré depuis un code maison, qui sera utilisé pour générer du code assembleur bas niveau</i></div></br>Le code source de ce projet est disponible à l’adresse <a href='https://github.com/Kakuno77/Compiler'>https://github.com/Kakuno77/Compiler</a> sur un repo github public qui peut être forké et utilisé par n’importe qui.</p>",
                      "customCss": {}
                  }
              ]
          }
      ]
  }
}