{
  "slug": "realisations",
  "title": "Mes réalisations",
  "content": {
      "articles": [
          {
              "banner": {
                  "headline": "lorem ipsum dolor amet",
                  "image": {
                      "src": "/img/ngsi.png",
                      "alt": ""
                  }
              },
              "title": "Migration du context broker Stellio vers Orion",
              "customCss": {},
              "direction": "row",
              "elements": [
                  {
                      "type": "text",
                      "sort": 2,
                      "content": "<p>La migration de Stellio vers Orion, deux context brokers NGSI-LD, représente une étape importante pour notre infrastructure de gestion de données.</br>Cette migration, réalisée sur un cluster Kubernetes, a permis de renforcer notre capacité à traiter et à gérer de grandes quantités de données contextuelles.</br>Cet article explique pourquoi et comment cette migration a été réalisée, les défis rencontrés et les bénéfices obtenus.<h2>Qu'est-ce qu'un context broker NGSI-LD ?</h2>Avant de plonger dans les détails techniques, il est essentiel de comprendre ce qu'est un context broker NGSI-LD.</br>Un context broker NGSI-LD est un type spécifique de context broker conforme à la norme NGSI-LD, qui définit un modèle de données et des interfaces pour représenter et interagir avec des données contextuelles en utilisant des technologies de données liées (Linked Data).</br> Ils sont largement utilisés dans les initiatives de villes intelligentes pour agréger, traiter et analyser des données provenant de capteurs répartis à travers la ville.</br>Cela permet aux autorités municipales et aux gestionnaires d'infrastructures de prendre des décisions basées sur des informations contextuelles actualisées.</br>Par exemple, optimiser la circulation, gérer la consommation d'énergie, améliorer la sécurité publique, etc.</br>Les brokers NGSI-LD, comme Stellio et Orion, sont des composants logiciels essentiels pour la gestion des données contextuelles dans les applications de l'Internet des Objets (IoT).</br>Ils permettent de collecter, stocker, gérer et interroger des données contextuelles en utilisant le standard NGSI-LD.</br><i>Les données contextuelles désignent les informations qui décrivent les circonstances environnementales, opérationnelles ou situationnelles pertinentes à un moment donné.</br>Ces données peuvent inclure des informations sur la localisation, la météo, les conditions de trafic, l'état des dispositifs IoT, etc.</br>Elles sont souvent dynamiques et nécessitent une mise à jour fréquente pour refléter les changements en temps réel.</i><h2>Pourquoi Migrer de Stellio à Orion ?</h2>Stellio et Orion sont deux implémentations de brokers NGSI-LD, chacune avec ses propres avantages et inconvénients.</br>La décision de migrer de Stellio à Orion a été motivée par plusieurs facteurs :<li><b>Performance</b> : Orion offre des performances supérieures en termes de traitement et de gestion des données contextuelles.</li><li><b>Compatibilité</b> : Orion est largement adopté et offre une meilleure compatibilité avec d'autres composants de notre écosystème technologique.</li><li><b>Support et Communauté</b> : Orion bénéficie d'un support actif et d'une communauté dynamique, facilitant la résolution des problèmes et l'accès aux nouvelles fonctionnalités.</li><h2>Le Processus de Migration</h2>La migration de Stellio à Orion sur Kubernetes a été réalisée en plusieurs étapes :<li><b>Planification et Préparation</b> : Une analyse approfondie a été effectuée pour comprendre les dépendances et les configurations requises. Un plan de migration détaillé a été élaboré.</li><li><b>Installation d'Orion</b> : Orion a été déployé sur Kubernetes en utilisant des fichiers de configuration YAML pour définir les déploiements, les services et les configurations nécessaires.</li><li><b>Migration des Données</b> : Les données existantes dans Stellio ont été exportées et importées dans Orion. Des scripts ont été utilisés pour automatiser ce processus et garantir l'intégrité des données.</li><li><b>Tests et Validation</b> : Des tests rigoureux ont été effectués pour s'assurer que toutes les données ont été migrées correctement et que Orion fonctionnait comme prévu.</li><li><b>Mise en Production</b> : Une fois les tests réussis, Orion a été mis en production et Stellio désinstallé. Une surveillance continue a été mise en place pour détecter et résoudre rapidement tout problème.</li><h2>Ce qu'on en a tiré</h2>Comme toute migration, celle-ci n'était pas sans défis, certaines structures de données dans Stellio n'étaient pas directement compatibles avec Orion, nécessitant des transformations spécifiques.</br>Assurer que toutes les dépendances externes fonctionnaient correctement avec Orion a demandé des ajustements et des tests supplémentaires.</br>Enfin nous avons travaillé pour minimiser les interruptions de service, en planifiant les migrations pendant les périodes de faible activité.</br>Cependant la migration vers Orion a apporté plusieurs bénéfices significatifs comme les temps de réponse pour les requêtes de données contextuelles ont été réduits, améliorant l'expérience utilisateur.</p>",
                      "customCss": {}
                  }
              ]
          },
          {
              "banner": {
                  "headline": "lorem ipsum dolor amet",
                  "image": {
                      "src": "/img/K8S-logo.png",
                      "alt": ""
                  }
              },
              "title": "Migration d'un cluster kubernetes",
              "customCss": {},
              "direction": "row",
              "elements": [
                  {
                      "type": "text",
                      "sort": 2,
                      "content": "<p> Dans le cadre de l'évolution de nos besoins en termes de performances et de scalabilité, nous avons récemment entrepris la migration d'un de nos clusters Kubernetes vers une infrastructure plus puissante. </br>Ce projet a été motivé par l'augmentation continue de la consommation de processeur et de RAM requis pour satisfaire les besoins de nos différents clients. <h2>Planification et Préparation</h2> La migration a été minutieusement planifiée par la direction des systèmes informatiques ainsi que l'équipe technique pour répondre à leurs exigences. </br>Les principaux objectifs identifiés étaient de garantir une transition fluide, de valider la pertinence des outils existants, et de mettre à jour les composants obsolètes. </br>Un aspect crucial de la préparation a été la sauvegarde des données. Les données des différents déploiements de notre ancien cluster étaient sauvegardées quotidiennement sur un bucket, un conteneur de stockage d'objets. J’ai donc vérifié que ces sauvegardes pouvaient être restaurées sans problème, garantissant ainsi l'intégrité des données durant la migration. <h2>Mise en Place du Nouveau Cluster</h2> La première étape technique a consisté à installer Kubernetes sur notre nouvelle machine. </br>Cette installation a été réalisée via un <b>pipeline CI/CD (Intégration Continue/Livraison Continue)</b> spécialement conçu pour automatiser les processus nécessaires. </br>Ce pipeline exécutait des jobs pour réinstaller les différentes applications conteneurisées qui composent la plateforme. </br>L'automatisation a joué un rôle clé dans la réinstallation des composants. </br>Dès le lancement des jobs, les applications conteneurisées ont été automatiquement déployées sur le nouveau cluster. </br> Une fois l'installation terminée, j’ai procédé à des vérifications pour m’assurer que toutes les applications fonctionnaient correctement. <h2>Migration des Données et Vérifications</h2> Après la réinstallation des composants, l'étape suivante a été de restaurer les backups sur le nouveau cluster, que j’ai personnellement effectué. </br>Ce processus a été réalisé en tirant les sauvegardes précédemment stockées sur le bucket vers la nouvelle infrastructure. </br>Cette étape cruciale a permis de transférer en toute sécurité les données de l'ancien cluster vers le nouveau. </br>Une fois les données restaurées, nous avons effectué des tests approfondis pour vérifier le bon fonctionnement des applications et la conformité des données. </br>Ces tests ont confirmé que la migration s'était déroulée sans accrocs. <h2>Conclusion et Expertise</h2> En résumé, cette migration de cluster Kubernetes a été un succès grâce à une planification rigoureuse et à l'automatisation des processus. </br>Mon expertise couvre l'ensemble des opérations de déploiement, de backup et de monitoring, où je me considère à un niveau intermédiaire. </br>Cependant, en ce qui concerne les opérations de routage telles que l'utilisation de reverse proxies ou de load balancers, je me situe encore à un niveau débutant. </br>Cette expérience enrichissante a renforcé mes compétences et ma capacité à répondre aux besoins croissants de nos clients, tout en garantissant la performance et la fiabilité de leurs applications.</p>",
                      "customCss": {}
                  }
              ]
          },
          {
              "banner": {
                  "headline": "lorem ipsum dolor amet",
                  "image": {
                      "src": "/img/s3.png",
                      "alt": ""
                  }
              },
              "title": "Déploiement et gestion de backups répliqués",
              "customCss": {},
              "direction": "row",
              "elements": [
                  {
                      "type": "text",
                      "sort": 3,
                      "content": "<p>Dans le monde dynamique des infrastructures cloud, la sauvegarde des données est essentielle.</br>Imaginez un scénario où plusieurs services tournent sur un cluster Kubernetes, chacun avec sa propre base de données à sauvegarder.</br>Sur ce cluster, nous avons déployé divers services, tels qu'Elasticsearch, MongoDB et PostgreSQL, chacun nécessitant une sauvegarde régulière de ses données.</br>Pour automatiser ce processus, j'ai mis en place des pods dédiés à chaque service. Ces pods exécutent quotidiennement un script bash qui réalise une sauvegarde.<h2>Mais comment ces pods savent-ils où sauvegarder les données ?</h2>C'est là que les termes endpoints et bucket entrent en jeu.</br>Un <b>endpoint</b> est essentiellement une adresse, un point d'accès, où les données peuvent être envoyées ou récupérées.</br>Dans notre cas, nous utilisons un endpoint S3, qui est un service de stockage d'objets offert par Amazon Web Services.</br>Le <b>bucket</b> est le conteneur principal dans lequel les données sont stockées sur S3.</br>Ainsi, chaque pod doit connaître l'endpoint S3 et le bucket correspondant pour y sauvegarder les données.</br>Mais ce n'est pas tout, nous voulons également une redondance pour assurer la sécurité de nos données.</br>Pour ce faire, je configure un second endpoint où une copie de sauvegarde, un replica, sera stockée.</br>Cela garantit que même en cas de problème avec le premier endpoint, nos données restent sécurisées et accessibles.<h2> Suivi et gestion des backups</h2></br>Pour simplifier la gestion de ce processus complexe, j'ai pour mon usage personnel crée un outil pratique : un tableau Excel répertoriant tous les services à sauvegarder.</br>Ce tableau contient des informations essentielles telles que le nom du service, le cluster sur lequel il est déployé, les endpoints et les buckets associés mais aussi où sont les réplicas de ces bases.</br> Je l'ai par la suite proposé à mes supérieurs qui ont accepté de l'exploiter.</br>Cette approche facilite la surveillance et la gestion de toutes les sauvegardes, offrant une vue d'ensemble claire de notre infrastructure.</br>En résumé, cette solution permet de simplifier et d'automatiser le processus de sauvegarde des données dans un environnement Kubernetes complexe.<h2>Conclusion</h2>En combinant des scripts automatisés, une configuration précise des endpoints et des buckets, ainsi qu'un outil de gestion centralisé, j'assure la sécurité et la disponibilité des données de manière efficace et fiable.</p>",
                      "customCss": {}
                  }
              ]
          }
      ]
  }
}